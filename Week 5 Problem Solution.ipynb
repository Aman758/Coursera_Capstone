{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project: Week 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the project\n",
    "1. The following script helps potential clients who are looking to buy suitable property in London\n",
    "2. With a pre-determined budged, this automation will recommend you locations and current average price of real estate where one can make a real estate investment\n",
    "3. Important amenities/ venues for each recommended location are displayed\n",
    "4. Facilities like elementary schools, high schools, hospitals & grocery stores are displayed for each recommended location¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Import_ Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.8.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs: \n",
      "    - geopy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.11.28         |           py36_0         149 KB  conda-forge\n",
      "    scikit-learn-0.20.1        |   py36h22eb022_0         5.7 MB\n",
      "    liblapack-3.8.0            |      11_openblas          10 KB  conda-forge\n",
      "    numpy-1.18.1               |   py36h95a1406_0         5.2 MB  conda-forge\n",
      "    liblapacke-3.8.0           |      11_openblas          10 KB  conda-forge\n",
      "    geographiclib-1.50         |             py_0          34 KB  conda-forge\n",
      "    libopenblas-0.3.6          |       h5a2b251_2         7.7 MB\n",
      "    scipy-1.4.1                |   py36h921218d_0        18.9 MB  conda-forge\n",
      "    geopy-1.21.0               |             py_0          58 KB  conda-forge\n",
      "    libcblas-3.8.0             |      11_openblas          10 KB  conda-forge\n",
      "    libblas-3.8.0              |      11_openblas          10 KB  conda-forge\n",
      "    blas-2.11                  |         openblas          10 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        37.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    geographiclib: 1.50-py_0                              conda-forge\n",
      "    geopy:         1.21.0-py_0                            conda-forge\n",
      "    libblas:       3.8.0-11_openblas                      conda-forge\n",
      "    libcblas:      3.8.0-11_openblas                      conda-forge\n",
      "    liblapack:     3.8.0-11_openblas                      conda-forge\n",
      "    liblapacke:    3.8.0-11_openblas                      conda-forge\n",
      "    libopenblas:   0.3.6-h5a2b251_2                                  \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    blas:          1.1-openblas                           conda-forge --> 2.11-openblas         conda-forge\n",
      "    certifi:       2019.9.11-py36_0                       conda-forge --> 2019.11.28-py36_0     conda-forge\n",
      "    numpy:         1.16.2-py36_blas_openblash1522bff_0    conda-forge [blas_openblas] --> 1.18.1-py36h95a1406_0 conda-forge\n",
      "    scipy:         1.2.1-py36_blas_openblash1522bff_0     conda-forge [blas_openblas] --> 1.4.1-py36h921218d_0  conda-forge\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    scikit-learn:  0.20.1-py36_blas_openblashebff5e3_1200 conda-forge [blas_openblas] --> 0.20.1-py36h22eb022_0            \n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2019.11.28   | 149 KB    | ##################################### | 100% \n",
      "scikit-learn-0.20.1  | 5.7 MB    | ##################################### | 100% \n",
      "liblapack-3.8.0      | 10 KB     | ##################################### | 100% \n",
      "numpy-1.18.1         | 5.2 MB    | ##################################### | 100% \n",
      "liblapacke-3.8.0     | 10 KB     | ##################################### | 100% \n",
      "geographiclib-1.50   | 34 KB     | ##################################### | 100% \n",
      "libopenblas-0.3.6    | 7.7 MB    | ##################################### | 100% \n",
      "scipy-1.4.1          | 18.9 MB   | ##################################### | 100% \n",
      "geopy-1.21.0         | 58 KB     | ##################################### | 100% \n",
      "libcblas-3.8.0       | 10 KB     | ##################################### | 100% \n",
      "libblas-3.8.0        | 10 KB     | ##################################### | 100% \n",
      "blas-2.11            | 10 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Solving environment: / "
     ]
    }
   ],
   "source": [
    "import os # Operating System\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt # Datetime\n",
    "import json # library to handle JSON files\n",
    "\n",
    "!conda install -c conda-forge geopy --yes\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium #import folium # map rendering library\n",
    "!conda install -c anaconda xlrd --yes\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Library for Geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geocoder\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/6b/13166c909ad2f2d76b929a4227c952630ebaf0d729f6317eb09cbceccbab/geocoder-1.38.1-py2.py3-none-any.whl (98kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 6.1MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting ratelim (from geocoder)\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/98/7e6d147fd16a10a5f821db6e25f192265d6ecca3d82957a4fdd592cad49c/ratelim-0.1.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from geocoder) (2.22.0)\n",
      "Collecting future (from geocoder)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 16.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from geocoder) (1.13.0)\n",
      "Collecting click (from geocoder)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 16.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from ratelim->geocoder) (4.4.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests->geocoder) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests->geocoder) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests->geocoder) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests->geocoder) (2019.9.11)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "Successfully built future\n",
      "Installing collected packages: ratelim, future, click, geocoder\n",
      "Successfully installed click-7.0 future-0.18.2 geocoder-1.38.1 ratelim-0.1.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium # map rendering library\n",
    "import time\n",
    "import geocoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset and primary processing\n",
    "#### Source of dataset: http://landregistry.data.gov.uk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data for examination (Source: http://landregistry.data.gov.uk/)\n",
    "df_ppd = pd.read_csv(\"http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-monthly-update-new-version.csv\")\n",
    "\n",
    "# Assign meaningful column names\n",
    "df_ppd.columns = ['TUID', 'Price', 'Date_Transfer', 'Postcode', 'Prop_Type', 'Old_New', 'Duration', 'PAON', \\\n",
    "                  'SAON', 'Street', 'Locality', 'Town_City', 'District', 'County', 'PPD_Cat_Type', 'Record_Status']\n",
    "# Format the date column\n",
    "df_ppd['Date_Transfer'] = df_ppd['Date_Transfer'].apply(pd.to_datetime)\n",
    "\n",
    "# Delete all obsolete transactions which were done before 2016\n",
    "df_ppd.drop(df_ppd[df_ppd.Date_Transfer.dt.year < 2016].index, inplace=True)\n",
    "\n",
    "# Sort by Date of Sale\n",
    "df_ppd.sort_values(by=['Date_Transfer'],ascending=[False],inplace=True)\n",
    "df_ppd_london = df_ppd.query(\"Town_City == 'LONDON'\")\n",
    "\n",
    "# Make a list of street names in LONDON\n",
    "streets = df_ppd_london['Street'].unique().tolist()\n",
    "df_grp_price = df_ppd_london.groupby(['Street'])['Price'].mean().reset_index()\n",
    "\n",
    "# Give meaningful names to the columns\n",
    "df_grp_price.columns = ['Street', 'Avg_Price']\n",
    "\n",
    "df_affordable = df_grp_price.query(\"(Avg_Price >= 2200000) & (Avg_Price <= 2500000)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Street</th>\n",
       "      <th>Avg_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AGATE ROAD</td>\n",
       "      <td>2.240000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ANHALT ROAD</td>\n",
       "      <td>2.250000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>ASHINGTON ROAD</td>\n",
       "      <td>2.375000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>BEECH DRIVE</td>\n",
       "      <td>2.215000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>BELSIZE LANE</td>\n",
       "      <td>2.366667e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Street     Avg_Price\n",
       "31       AGATE ROAD  2.240000e+06\n",
       "99      ANHALT ROAD  2.250000e+06\n",
       "140  ASHINGTON ROAD  2.375000e+06\n",
       "255     BEECH DRIVE  2.215000e+06\n",
       "272    BELSIZE LANE  2.366667e+06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_affordable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geocoder starts here\n",
    "# Defining a function to use --> get_latlng()\n",
    "def get_latlng(arcgis_geocoder):\n",
    "    \n",
    "    # Initialize the Location (lat. and long.) to \"None\"\n",
    "    lat_lng_coords = None\n",
    "    \n",
    "    # While loop helps to create a continous run until all the location coordinates are geocoded\n",
    "    while(lat_lng_coords is None):\n",
    "        g = geocoder.arcgis('{},United Kingdom'.format(arcgis_geocoder))\n",
    "        lat_lng_coords = g.latlng\n",
    "    return lat_lng_coords\n",
    "# Geocoder ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the coordinates for the streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of execution:  20.01204824447632 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Street</th>\n",
       "      <th>Avg_Price</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AGATE ROAD</td>\n",
       "      <td>2240000.0</td>\n",
       "      <td>51.51459</td>\n",
       "      <td>-0.19888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Street  Avg_Price  Latitude  Longitude\n",
       "31  AGATE ROAD  2240000.0  51.51459   -0.19888"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying it to our dataframe:\n",
    "start = time.time()\n",
    "\n",
    "Headquarter = df_affordable['Street']    \n",
    "coordinates = [get_latlng(Headquarter) for Headquarter in Headquarter.tolist()]\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time of execution: \", end - start, \"seconds\")\n",
    "\n",
    "london_data = df_affordable\n",
    "\n",
    "# The obtained coordinates (latitude and longitude) are joined with the dataframe as shown\n",
    "df_coordinates = pd.DataFrame(coordinates, columns = ['Latitude', 'Longitude'])\n",
    "london_data['Latitude'] = df_coordinates['Latitude']\n",
    "london_data['Longitude'] = df_coordinates['Longitude']\n",
    "#df_delhi.to_csv('DelhiHeadquarterCoordinates.csv', index = False)\n",
    "london_data = london_data.dropna(how ='any',axis=0)\n",
    "london_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your credentails:\n",
      "CLIENT_ID: GLOQ4Y14EA0FSVRORBXI0WP0NHC0GMUX5SACBXSQK3DXJDAB\n",
      "CLIENT_SECRET:KICYXPZM4LFJ03EQXSRXJNBBZ0NVMTDQCTZK131M5BADYJZV\n"
     ]
    }
   ],
   "source": [
    "CLIENT_ID = 'GLOQ4Y14EA0FSVRORBXI0WP0NHC0GMUX5SACBXSQK3DXJDAB' # your Foursquare ID\n",
    "CLIENT_SECRET = 'KICYXPZM4LFJ03EQXSRXJNBBZ0NVMTDQCTZK131M5BADYJZV' # your Foursquare Secret\n",
    "VERSION = '20180604'\n",
    "LIMIT = 30\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        \n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit=100'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the street-wise coordinates into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pref_loc = pd.merge(london_data, df_affordable, on=['Street'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pref_loc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot recommended locations on map of London with current market prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'London, UK'\n",
    "geolocator = Nominatim()\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of London City are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of Manhattan using latitude and longitude values\n",
    "map_london = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, price, street in zip(df_pref_loc['Latitude'], df_pref_loc['Longitude'], df_pref_loc['Avg_Price'], df_pref_loc['Street']):\n",
    "    label = '{}, {}'.format(street, price)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_london)  \n",
    "    \n",
    "map_london"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Foursquare Credentials and Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = '******' # your Foursquare ID\n",
    "CLIENT_SECRET = '*******' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's explore the first neighborhood in our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the preferred location for different venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500, LIMIT=100):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Street', \n",
    "                  'Street Latitude', \n",
    "                  'Street Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now write the code to run the above function on each location and create a new dataframe called location_venues and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type your answer here\n",
    "location_venues = getNearbyVenues(names=df_pref_loc['Street'],\n",
    "                                   latitudes=df_pref_loc['Latitude'],\n",
    "                                   longitudes=df_pref_loc['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_venues.groupby('Street').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore the first neighborhood in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyFacility(names, latitudes, longitudes, radius=5000):\n",
    "    \n",
    "    facility_list=[]\n",
    "    \n",
    "    radius = 5000\n",
    "    LIMIT = 100\n",
    "    categories = '4bf58dd8d48988d196941735,58daa1558bbb0b01f18ec1f7,4bf58dd8d48988d13d941735,4f4533804b9074f6e4fb0105,4bf58dd8d48988d118951735'\n",
    "    \n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/search?&categoryId={}&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "        categories,\n",
    "        CLIENT_ID, \n",
    "        CLIENT_SECRET, \n",
    "        VERSION, \n",
    "        lat, \n",
    "        lng, \n",
    "        radius, \n",
    "        LIMIT)\n",
    "\n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()['response']\n",
    "\n",
    "        # return only relevant information for each nearby venue\n",
    "        facility_list.append([(\n",
    "            name,\n",
    "            facility['name'],\n",
    "            facility['categories'][0]['name'],\n",
    "            facility['location']['distance'], \n",
    "            facility['location']['lat'],\n",
    "            facility['location']['lng']) for facility in results['venues']])\n",
    "\n",
    "    nearby_facility = pd.DataFrame([item for f_list in facility_list for item in f_list])\n",
    "    nearby_facility.columns = ['Street Name',\n",
    "                  'Facility Name',             \n",
    "                  'Facility Category', \n",
    "                  'Distance', \n",
    "                  'Facility Latitude', \n",
    "                  'Facility Longitude']\n",
    "    \n",
    "    return(nearby_facility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_facility = getNearbyFacility(names=df_pref_loc['Street'],\n",
    "                                      latitudes=df_pref_loc['Latitude'],\n",
    "                                      longitudes=df_pref_loc['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_facility.groupby('Street Name').count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
